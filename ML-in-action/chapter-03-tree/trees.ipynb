{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 信息熵（熵越高，数据越混乱）\n",
    "\n",
    "$$\n",
    "H=-\\sum _{i=1}^{n} p(x_i) \\log_2 p(x_i)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code: 3-1\n",
    "from math import log  # 导入对数\n",
    "\n",
    "def calc_shannon_ent(dataset):\n",
    "    \"\"\"\n",
    "    计算信息增益\n",
    "    :param dataset: 数据集\n",
    "    :return : 信息熵\n",
    "    \"\"\"\n",
    "    num = len(dataset)\n",
    "    lab_num = {}\n",
    "    # 为所有分类创建字典\n",
    "    for feat in dataset:\n",
    "        label = feat[-1]\n",
    "        if label not in lab_num.keys():\n",
    "            lab_num[label] = 0\n",
    "        lab_num[label] += 1\n",
    "    \n",
    "    # 计算信息熵\n",
    "    shannon_ent = 0.0\n",
    "    for key in lab_num:\n",
    "        prob = float(lab_num[key])/num\n",
    "        shannon_ent -= prob * log(prob, 2)\n",
    "    return shannon_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset = [\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "    ]\n",
    "    lables = ['no surfacing', 'flippers']\n",
    "    return dataset, lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "['no surfacing', 'flippers']\n"
     ]
    }
   ],
   "source": [
    "my_data, labels = create_dataset()\n",
    "print(my_data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_shannon_ent(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data[0][-1] = 'maybe'\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_shannon_ent(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code: 3-2\n",
    "\n",
    "def splite_data(dataset, axis, value):\n",
    "    \"\"\"\n",
    "    分割数据\n",
    "    :param dataset: 要分割的数据集\n",
    "    :param axis: 维度，会删掉axis维的数据\n",
    "    :param value: 该维度对应的值\n",
    "    :return : 信息熵\n",
    "    \"\"\"\n",
    "    res = []  # 创建的新的list对象\n",
    "    for data in dataset:\n",
    "        if data[axis] == value:\n",
    "            # 跳过第i个属性值\n",
    "            reduced_dataset = data[:axis]\n",
    "            reduced_dataset.extend(data[axis + 1:])  # 追加\n",
    "            res.append(reduced_dataset)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 函数测试\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'maybe'], [1, 'yes'], [0, 'no'], [0, 'no']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splite_data(my_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code: 3-3\n",
    "\n",
    "def choose_best_feat(dataset):\n",
    "    \"\"\"\n",
    "    选择最好的分割属性\n",
    "    :param dataset: 要分割的数据集\n",
    "    :return : 属性i\n",
    "    \"\"\"\n",
    "    feat_num = len(dataset[0]) - 1  # 特征数量\n",
    "    base_entropy = calc_shannon_ent(dataset)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = -1\n",
    "    for i in range(feat_num):\n",
    "        # 创建第i个特征的列表\n",
    "        feat_list = [example[i] for example in dataset]\n",
    "        unique_vals = set(feat_list)  # 去掉重复值\n",
    "        \n",
    "        # 计算每种划分方式的信息熵\n",
    "        new_entroy = 0.0\n",
    "        for val in unique_vals:\n",
    "            subdata = splite_data(dataset, i, val)\n",
    "            prob = len(subdata)/float(len(dataset))\n",
    "            new_entroy += prob * calc_shannon_ent(subdata)\n",
    "        info_gain = base_entropy - new_entroy\n",
    "        \n",
    "        # 计算最好的信息熵\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_best_feat(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def majority_cnt(class_list):\n",
    "    \"\"\"\n",
    "    获取类别最多的类标记\n",
    "    :param class_list: 类别列表\n",
    "    :return : 类别最多的类标记\n",
    "    \"\"\"\n",
    "    class_count = {}\n",
    "    for vote in class_list:\n",
    "        if vote not in class_count.keys():\n",
    "            class_count[vote] = 0\n",
    "        class_count[vote] += 1\n",
    "    sorted_class_count = sorted(class_count.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_class_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code: 3-4\n",
    "\n",
    "def create_tree(dataset, labels):\n",
    "    \"\"\"\n",
    "    创建树\n",
    "    :param dataset: 数据集\n",
    "    :param labels: 标签列表，包含在dataset中，但为了给出数据明确的含义，将他作为一个输入参数提供\n",
    "    :return : \n",
    "    \"\"\"\n",
    "    class_list = [example[-1] for example in dataset]\n",
    "    \n",
    "    # 停止条件：所有的类标签完全相同\n",
    "    if class_list.count(class_list[0]) == len(class_list):\n",
    "        return class_list[0]\n",
    "    \n",
    "    # 停止条件：使用完所有特征，仍不能将数据集正确划分\n",
    "    if len(dataset[0]) == 1:\n",
    "        return majority_cnt(class_list)\n",
    "    \n",
    "    best_feat = choose_best_feat(dataset)\n",
    "    best_feat_label = labels[best_feat]\n",
    "    my_tree = {best_feat_label:{}}\n",
    "    \n",
    "    # 得到列表包含的所有属性值\n",
    "    del(labels[best_feat])\n",
    "    feat_val = [example[best_feat] for example in dataset]\n",
    "    unique_val = set(feat_val)\n",
    "    \n",
    "    for val in unique_val:\n",
    "        sub_labels = labels[:]\n",
    "        my_tree[best_feat_label][val] = create_tree(splite_data(dataset, best_feat, val), sub_labels)\n",
    "        \n",
    "    return my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myTree:  {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "my_data, labels = create_dataset()\n",
    "myTree = create_tree(my_data, labels)\n",
    "print('myTree: ', myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code:3-8\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    \"\"\"\n",
    "    决策树的分类函数\n",
    "    \"\"\"\n",
    "    first_str = list(inputTree.keys())[0]\n",
    "    # {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
    "    second_dict = inputTree[first_str]\n",
    "    featIndex = featLabels.index(first_str) # 标签字符串转换为索引\n",
    "    for key in second_dict.keys():`\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(second_dict[key]).__name__=='dict':\n",
    "                classLabel = classify(second_dict[key], featLabels, testVec)\n",
    "            else:\n",
    "                classLabel = second_dict[key]\n",
    "    return classLabel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no surfacing', 'flippers']\n",
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
      "no\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import treePlotter\n",
    "my_data, labels = create_dataset()\n",
    "print(labels)\n",
    "myTree = treePlotter.retrieve_tree(0)\n",
    "print(myTree)\n",
    "print(classify(myTree, labels, [1,0]))\n",
    "print(classify(myTree, labels, [1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
